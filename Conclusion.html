<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Conclusion - Gesture Based User Interface</title>
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/scrolling-nav.css" rel="stylesheet">

    <style type="text/css">
    .center {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 50%;
    }

    .center-qsys {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 100%;
    }

    .center-ui {
      display: block;
      margin-left: auto;
      margin-right: auto;
    }

    table {
      font-family: arial, sans-serif;
      border-collapse: collapse;
      width: 100%;
    }

    td, th {
      border: 1px solid #dddddd;
      text-align: left;
      padding: 8px;
    }

    tr:nth-child(even) {
      background-color: #dddddd;
    }

    .rotateimg180 {
      -webkit-transform:rotate(180deg);
      -moz-transform: rotate(180deg);
      -ms-transform: rotate(180deg);
      -o-transform: rotate(180deg);
      transform: rotate(180deg);
    }
    </style>

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Gesture Based User Interface</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Introduction.html">Introduction</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="High%20Level%20Design.html">High Level</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Hardware.html">Hardware</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Software.html">Software</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Results.html">Results</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Conclusion.html">Conclusion</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="References.html">References</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Appendix.html">Appendices</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <header style="background-color: #696969" class="text-white">
      <div class="container text-center">
        <h1>ECE 5760 Final Project: Gesture Based User Interface</h1>
        <h2>Conclusion</h2>
        <br>
        <!-- <img class="center-qsys" src="images/setup.PNG" alt="Setup"> -->
      </div>
    </header>

    <section id="Introduction" class="bg-light">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 mx-auto">
            <p class="lead">The team’s initial goal of designing and implementing a gesture based using color detection is successfully satisfied. We were able to interface with the NTSC camera, interconnect the camera feed with the FPGA, perform color detection, create HPS graphics, overlay the camera feed with the HPS graphics, enable audio from the HPS, and display images onto the VGA screen via the HPS. In accomplishing all the above-mentioned tasks, we have significantly exceeded our initial expectations showcased in the project proposal. </p>
            <p class="lead">While the project can be considered a success, there are several aspects of the design we may have done differently if we were to redo the project. One of the things we would do differently is modify the pixel boxes to be a quarter of their current size. Currently we have 1200 pixel boxes (40 wide x 30 high) that allow for the detection to occur when a certain number of pixels in them detect the color blue. If these boxes are smaller, it will make the hits even more precise and could possibly pick up the blue pixels from a greater distance from the camera. Another aspect of the project we could approach differently is to store the HPS feed into the SDRAM so that we can enable full resolution and full color. Currently, we are utilizing 320 x 240 resolution and 8 bit RGB color. We could also explore different color detection schemes. For example, instead of checking if the blue pixels are greater than green + red pixels combined, we could base the detection on the ratio of blue pixels compared to the ratio of green + pixels. This scheme may assist in better detecting blue pixels and optimize the detection accuracy. We could have explored de-interlacing the video stream for better video quality. Moreover, we could have played a video stream to the VGA from the HPS, as an extension to the image rendering from the HPS. Lastly, we could have added to the HPS graphics by highlighting the drum that was hit. This can help in showcasing exactly which drum was hit and when it was hit, adding to the overall system usability. 
            <p class="lead">This project followed and conformed to the typical standards implemented by IEEE, ANSI, and ISO for design related to hardware description languages, software development, communication, testing, specifications, and documentation. Various standards corresponding to the Altera DE1 - SoC FPGA development board were also implicated in this project. Some measures were taken to ensure safety for the users. We used very light wooden sticks and covered their tips with paper towel and tape so that the risk of injury from being struck by the stick is minimized. Moreover, the pixel detection works the best when the user is withing a meter of the camera. This allows the user to be right beside the workstation minimizing the chances of hitting a bystander in the surroundings. 
            <p class="lead">Intellectual property considerations under this project mostly pertained to the ECE 5760 – Advanced Microcontrollers resources and Altera DE1-SoC programs. The team utilized and referenced all of the example Verilog, C, and Qsys programs that were based off the ECE 5760 examples and past projects. Moreover, we also referenced the Qsys Altera DE1-SoC modules that we used for our video system. To the best of the team’s knowledge, no legal considerations could be identified as a part of this project. 
              <br>
            
            
          </div>
        </div>
      </div>
    </section>

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">Copyright &copy; Cornell University, ECE 5760 (Spring 2022)</p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom JavaScript for this theme -->
    <script src="js/scrolling-nav.js"></script>

  </body>

</html>
